# opcheck精度预检功能使用指南

提供加速库内置算子的精度预检能力，根据模型推理时dump的tensor及算子信息，计算标杆output，比较dump的算子output与标杆数据的误差，以检测算子精度是否达标。若使用旧版ait llm，请参考[精度预检能力使用说明](./v1.0/精度预检能力使用说明.md)。

## 1. 环境准备

***若不需要重新执行加速库单算子推理，可跳过步骤1***

### 1.1 cann包与atb包
```
source ./Ascend/ascend-toolkit/set_env.sh
source ./atb/set_env.sh
```
## 1.2 libopchecker.so包
- 从源码安装 ait_llm 时，如果配置了 `atb` 以及 `mindie-atb-models` 执行环境，会自动编译安装 `libopchecker.so`，不需要再手动编译
- 从 whl 包安装 ait_llm 时或安装时未配置 `atb` 以及 `mindie-atb-models` 执行环境，需要手动编译 `libopchecker.so`
  - 首先，进入llm所在目录
    - 若为源码安装，则进入源码目录，即`ait/ait/components/llm/ait_llm`
    - 若为pip安装，则进入安装目录，安装目录通过`python3 -c 'import ait_llm, os; print(os.path.dirname(os.path.abspath(ait_llm.__file__)))'`确定
  - 执行编译命令
    ```
    cd opcheck/atb_operators && bash build.sh
    ```
- 注：libopchecker.so 为预检底层，默认不打印日志，如确需启用其日志，可以执行`export LIB_OPCHECKER_LOG_ON=1`命令，设置为非1则日志恢复关闭状态。

## 2. 输入数据
### 2.1 数据落盘
使用`ait llm dump --exec "bash run.sh patches/models/modeling_xxx.py" --type tensor`将模型推理过程中的tensor数据落盘，-ids可指定索引，-opname可指定算子类型，-o可指定输出目录。
Dump默认落盘路径 `{DUMP_DIR}`在当前目录下，如果指定output目录，落盘路径则为指定的 `{OUTPUT_DIR}`。

- tensor信息会生成在默认落盘路径的atb_temp目录下，具体路径是 `{DUMP_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}`目录下。

注：`{PID}`为进程号；`{TID}`为 `token_id`。

## 3. 执行精度预检
### 3.1 使用示例
```bash
ait llm opcheck -i {OUTPUT_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}/
```
### 参数说明

| 参数名                      | 描述                                                         | 是否必选 |
| --------------------------- | ------------------------------------------------------------ | -------- |
| --input, -i                 | tensor数据路径，为文件夹，由ait llm dump --type tensor落盘，示例：{OUTPUT_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}/ | 是       |
| --output, -o                | 输出文件的保存路径，为文件夹，示例：xx/xxx/xx                | 否       |
| --operation-ids, -ids       | 选择预检指定索引的tensor，默认为空，全量算子预检。使用方式：-ids 24_1,2_3_5 | 否       |
| --operation-name, -opname   | 指定需要预检的算子类型，支持模糊指定，如selfattention只需要填写self。使用方式：-opname self,linear | 否       |
| --precision-metric, -metric | 指定需要输出的精度类型，可选范围：['abs', 'cos_sim'，'kl']，分别表示绝对误差通过率、余弦相似度、KL散度。默认为[]，即只输出相对误差通过率。使用方式：--metric kl cos_sim | 否       |
| --device-id, -device        | 指定需要使用的NPU设备，默认为0                               | 否       |
| --atb-rerun, -rerun         | 选择是否重新运行加速库单算子获得output，默认为false，即不运行加速库单算子，直接对比dump数据中的output。使用方式：-rerun | 否       |
| --custom-algorithms, -alg   | 指定自定义比对算法，格式应为“python_file_path.py:function”。自定义算法最好为独立文件，方法示例："def foo(golden_tensor, my_tensor): return float_value, string_message"，使用方式：-alg python_file_path.py:foo python_file_path.py:foo2| 否       |
| --csv-path, -c              | （新版本弃用）算子信息csv文件路径，为单个数据文件路径，由ait llm dump --type op落盘，示例：OUTPUT_DIR/ait_dump/operation_io_tensors/PID/operation_tensors_0.csv | 是       |

注：
- `{OUTPUT_DIR}/ait_dump/tensors/{device_id}_{PID}/{TID}`为tensor数据根目录，`-i`参数可接受根目录下任意子目录
- 不建议更改`OUTPUT_DIR`以外的路径名称，以免程序报错
- 新版本弃用`-c`参数，opcheck直接从tensor目录获取op_param.json读取算子信息。op_param.json会在dump tensor时默认dump在tensor目录下。

### 3.2 输出文件各列说明
|   表头   | 说明 |
| -------- | -------------------------------------------------- |
| op_id    | 算子id，以'_'分隔的算子拓扑结构名（从输入算子信息表中获取） |
| op_name  | 算子名称，格式为算子类名（参见[atb/infer_op_params.h中的Operation](https://www.hiascend.com/document/detail/zh/canncommercial/700/foundmodeldev/ascendtb/ascendtb_01_0045.html)） |
| op_param | 算子参数，同OpParam |
| tensor_path | 算子输入intensor的目录 |
| out_tensor_id |  算子输出outtensor的序号（部分算子输出可能有多个outtensor） |
| precision_standard | 采用的精度标准（参见3.3精度标准）|
| precision_result | 运行后的精度比对结果，PASS为精度通过，FAILED为精度不通过或者算子执行失败，addition failed为算子添加失败（不支持该算子类型）|
| rel_precision_rate(%) | 实际的精度通过率（使用相对误差，全部通过则为100%）|
| max_rel_error | 最大的相对误差值 |
| abs_precision_rate(%) | 实际的绝对误差精度通过率 |
| max_abs_error | 最大的绝对误差值 |
| cosine_similarity | 余弦相似度 |
| kl_divergence | kl散度 |
| fail_reason | 失败原因，包括精度未通过原因及算法执行失败原因 |

注：
- 后四列为可选项，可通过参数`-metric`指定
- 若通过参数`-alg`指定了自定义算法，比对结果将输出在`fail_reason`列之前

### 3.3 精度标准
每个DataType共有两项数据共同形成精度标准，其中第一项为误差级别，第二项为满足条件。例如，double对应的精度标准是满足Error小于0.0001误差级别的数据比例在99.99%以上，即双万分之一。
```
        self.precision_standard = {
            'torch.double': [error1, 99.99], 'torch.uint32': [error1, 99.99], 'torch.int64': [error1, 99.99],
            'torch.float': [error1, 99.99], 'torch.int32': [error1, 99.99], 'torch.uint64': [error1, 99.99],
            'torch.float16': [error3, 99.9], 'torch.bfloat16': [error4, 99.6], 'torch.int8': [error6, 99.9],
            'torch.uint8': [error6, 99], 'torch.int16': [error6, 99.9], 'torch.uint16': [error6, 99.9],
            'torch.bool': [error1, 100]
        }
```

注：error1: 0.0001, error2: 0.0005, error3: 0.001, error4: 0.004, error5: 0.005, error6: 1

## 3. 精度预检算子用例支持情况
| 算子名称 | 310IDUO | Atlas 800I A2 |
| -------- | --------- | ---------- |
| ActivationOperation | 不支持 | 支持 |
| AllGatherOperation | 不支持 | 支持 |
| AllReduceOperation | 不支持 | 支持 |
| AsStridedOperation | 支持 | 支持 |
| BroadcastOperation | 不支持 | 支持 |
| ConcatOperation | 支持 | 支持 |
| CumsumOperation | 支持 | 支持 |
| ElewiseOperation | 支持 | 支持 |
| FastSoftMaxGradOperation | 不支持 | 支持 |
| FastSoftMaxOperation | 不支持 | 支持 |
| FillOperation | 支持 | 支持 |
| GatherOperation | 支持 | 支持 |
| GenAttentionMaskOperation | 支持 | 支持 |
| IndexAddOperation | 支持 | 支持 |
| KvCacheOperation | 不支持 | 支持 |
| LayerNormOperation | 支持 | 支持 |
| LinearOperation | 支持 | 支持 |
| LinearParallelOperation | 不支持 | 支持 |
| LinearSparseOperation | 支持 | 不支持 |
| MultinomialOperation | 支持 | 支持 ||
| NonzeroOperation | 支持 | 支持 ||
| OnehotOperation | 支持 | 支持 ||
| PadOperation | 支持 | 支持 |
| PadWithHiddenStateOperation | 支持 | 支持 |
| PagedAttentionOperation | 不支持 | 支持 |
| ReduceOperation | 支持 | 支持 |
| RepeatOperation | 支持 | 支持 |
| ReshapeAndCacheOperation | 不支持 | 支持 |
| RmsNormBackwardOperation | 不支持 | 支持 |
| RmsNormOperation | 不支持 | 支持 |
| RopeGradOperation | 支持 | 支持 |
| RopeOperation | 支持 | 支持 |
| SelfAttentionOperation | 不支持 | 支持 |
| SetValueOperation | 支持 | 支持 |
| SliceOperation | 支持 | 支持 |
| SoftmaxOperation | 支持 | 支持 |
| SortOperation | 支持 | 支持 |
| SplitOperation | 支持 | 支持 |
| StridedBatchMatmulOperation | 支持 | 支持 |
| TopkToppSamplingOperation | 支持 | 支持 |
| TransdataOperation | 支持 | 支持 |
| TransposeOperation | 支持 | 支持 |
| UnpadOperation | 支持 | 支持 |
| UnpadWithHiddenStateOperation | 支持 | 支持 |
| WhereOperation | 支持 | 支持 |

*注：此为精度预检用例支持设备，算子支持设备请查询atb相关文档